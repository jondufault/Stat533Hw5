---
title: "Homework 5"
author: "Alena Shakhnovich, Nic Walling, Jonathan Dufault"
date: "September 29, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

### Algorithm 6.1

> #### Algorithm 6.1: Best subset selection
>
>1. Let $\mathcal{M}_0$ denote the null model, which contains no predictors. This
model simply predicts the sample mean for each observation.
>2. For k = 1, 2,...p:
> (a) Fit all ${p\choose k}$ models that contain exactly k predictors.
> (b) Pick the best among these ${p \choose k}$ models, and call it $\mathcal{M}_k$. Here best is defined as having the smallest RSS, or equivalently largest $R^2$.
> 3. Select a single best model from among $\mathcal{M}_0,\cdots,\mathcal{M}_p$ using cross-validated prediction error, Cp (AIC), BIC, or adjusted R2.




```{r}


# ALMO_ETIP : A Linear Model Over-Engineered To Impress Professor

ALMO_ETIP <- setRefClass("LinearModel",
                           fields=c("dataset",
                                    "response",
                                    ".trainDataset",
                                    ".testDataset",
                                    ".k",
                                    ".featureNames"
                                    ),
                           methods = list(
                             
                             # Initializer function creates 
                             
                             initialize = function(dataset,response,p=0.1){
                               
                               # Deliniates what data is available to predict our response
                               # and the response
                               .self$dataset = dataset
                               .self$response = response
                               .self$.featureNames = colnames(dataset)[colnames(dataset)!=response]
                               
                               # Hoping this saves some computation
                               .self$.k = ncol(dataset) - 1
                               
                               # The test/train data will be used for cross-validation
                               testIndex = .createTestAndTrainDataset(p)
                               .self$.trainDataset = dataset[-c(testIndex),]
                               .self$.testDataset = dataset[testIndex,]
                              
                               },
                             
                             .createTestAndTrainDataset = function(testPct){
                               # Divide the dataset into test and training data based
                               # on the percentage desired to hold for testing
                               n = nrow(.self$dataset)
                               testSize = testPct*n
                               testDataIndex = sample(1:n,testSize)
                               return(testDataIndex)
                             },
                             
                             .crossValidate = function(model,criteria="AdjR2"){
                               print("ma")
                             }
                             
                           )
                           )

ALMO_ETIP$methods(findBestSubset = function(){
  # Let's first Naiively find the best model at each number of features
  bestModelWithiFeatures = list()
  for (i in 1:.self$.k){
    # Easier and clearer to make the objects I'll iterate through,
    # so the code is easier to read
    kChooseiIndices = combn(1:.self$.k,i)

    
    # Can't really think of any better way to do this than "MAX=0, IF GREATER NEW MAX"
    bestr2 = 0
    bestModel = 999
    
    for (j in 1:ncol(kChooseiIndices)){
   
      candidateiFeatures = .self$.featureNames[kChooseiIndices[,j]]

      # This was an unwieldy formula, so I split it up into builders
      xPartOfFormula = paste(candidateiFeatures,collapse="+")
      regressionFormula = as.formula(paste(.self$response,"~",xPartOfFormula))
      
      
      candidateModel = lm(regressionFormula,data=.self$.trainDataset)
      
      if(summary(candidateModel)$r.squared>bestr2){
        bestModel = candidateModel
        bestr2 = summary(candidateModel)$r.squared
      }
    
    }  
      if(bestr2==0){
        stop("Something has gone horribly wrong.")
      }
      else{
        bestModelWithiFeatures[[i]] = bestModel

      }
    

      
    
    
      
  }
  # Next lest find the best model among the best models. 
  
  bestr2 = 0
  bestModel = NA
  for (modelK in bestModelWithiFeatures){
    if(summary(modelK)$adj.r.squared>bestr2){
      bestr2=summary(modelK)$adj.r.squared
      bestModel = modelK
    }
  }
  return(modelK)
}
)

x = ALMO_ETIP$new(dataset=iris[,-c(5)],
                    response="Sepal.Length"
)


x$findBestSubset()

```



### Algorithm 6.2


### Algorithm 6.3


## Problem 2


## Problem 3

## Problem 4

### Question 5

### Question 6

### Question 9

